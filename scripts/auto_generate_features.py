# auto_generate_features.py
import glob
import os
from pathlib import Path

import pandas as pd


def infer_feast_type(dtype):
    """Convert pandas dtype to FEAST type"""
    dtype_str = str(dtype).lower()

    if "int" in dtype_str:
        return "Int64" if "64" in dtype_str else "Int32"
    elif "float" in dtype_str:
        return "Float64" if "64" in dtype_str else "Float32"
    elif "bool" in dtype_str:
        return "Int32"
    elif "object" in dtype_str or "string" in dtype_str:
        return "String"
    elif "datetime" in dtype_str:
        return "UnixTimestamp"
    else:
        return "String"


def detect_entity(df):
    """Automatically detect entity column"""
    # Look for columns starting with 'id_' and ending with '_id'
    entity_cols = [
        col for col in df.columns if col.startswith("id_") and col.endswith("_id")
    ]

    if not entity_cols:
        return None, None

    # Use the first entity column found
    entity_col = entity_cols[0]

    # Extract entity name (e.g., 'id_worker_id' -> 'worker')
    entity_name = entity_col.replace("id_", "").replace("_id", "")

    return entity_col, entity_name


def generate_view_name(filename):
    """Generate feature view name from filename"""
    # Remove .parquet extension
    name = filename.replace(".parquet", "")

    # Remove common prefixes/suffixes
    name = name.replace("_features", "").replace("features_", "")

    return name


def scan_parquet_files(data_dir="data"):
    """Scan directory for all parquet files"""
    pattern = os.path.join(data_dir, "*.parquet")
    files = glob.glob(pattern)

    # Exclude registry and temp files
    files = [
        f for f in files if "registry" not in f.lower() and "temp" not in f.lower()
    ]

    return sorted(files)


def analyze_file(filepath):
    """Analyze a parquet file and extract metadata"""
    df = pd.read_parquet(filepath)
    filename = os.path.basename(filepath)

    entity_col, entity_name = detect_entity(df)

    # Get feature columns (exclude entity and timestamp columns)
    skip_cols = {"event_timestamp", "created_at"}
    if entity_col:
        skip_cols.add(entity_col)

    feature_cols = [col for col in df.columns if col not in skip_cols]

    return {
        "filepath": filepath,
        "filename": filename,
        "entity_col": entity_col,
        "entity_name": entity_name,
        "feature_cols": feature_cols,
        "df": df,
        "view_name": generate_view_name(filename),
    }


def generate_feast_code(data_dir="data", output_file="auto_features.py"):
    """Generate complete FEAST feature definitions"""

    print("=" * 80)
    print("Auto-Generating FEAST Features")
    print("=" * 80)

    # Scan for parquet files
    parquet_files = scan_parquet_files(data_dir)

    if not parquet_files:
        print(f"âŒ No parquet files found in {data_dir}/")
        return

    print(f"\nâœ… Found {len(parquet_files)} parquet file(s)")

    # Analyze all files
    file_metadata = []
    entities_map = {}  # Track unique entities

    for filepath in parquet_files:
        try:
            metadata = analyze_file(filepath)
            file_metadata.append(metadata)

            print(f"\nğŸ“„ {metadata['filename']}")
            print(f"   Entity: {metadata['entity_col']} ({metadata['entity_name']})")
            print(f"   Features: {len(metadata['feature_cols'])}")

            # Track entities
            if metadata["entity_name"]:
                entities_map[metadata["entity_name"]] = metadata["entity_col"]

        except Exception as e:
            print(f"\nâŒ Error processing {filepath}: {e}")

    # Generate code
    with open(output_file, "w") as f:
        # Header
        f.write("""# auto_features.py
# Auto-generated FEAST feature definitions
# Generated by: auto_generate_features.py
# DO NOT EDIT MANUALLY - Regenerate using: python auto_generate_features.py

from datetime import timedelta
from feast import Entity, FeatureView, Field, FileSource, ValueType
from feast.types import Float32, Float64, Int32, Int64, String, UnixTimestamp

""")

        # Generate entities
        f.write("# " + "=" * 76 + "\n")
        f.write("# ENTITIES\n")
        f.write("# " + "=" * 76 + "\n\n")

        for entity_name, entity_col in sorted(entities_map.items()):
            f.write(f"{entity_name} = Entity(\n")
            f.write(f'    name="{entity_col}",\n')
            f.write(f'    description="{entity_name.title()} identifier",\n')
            f.write(f"    value_type=ValueType.INT64,\n")
            f.write(f")\n\n")

        # Generate feature views
        f.write("\n# " + "=" * 76 + "\n")
        f.write("# FEATURE VIEWS\n")
        f.write("# " + "=" * 76 + "\n\n")

        for metadata in file_metadata:
            if not metadata["entity_name"]:
                f.write(
                    f"# Skipping {metadata['filename']} - no entity column found\n\n"
                )
                continue

            view_name = metadata["view_name"]
            source_name = f"{view_name}_source"

            # Comment header
            f.write(f"# {view_name.upper().replace('_', ' ')}\n")
            f.write(f"# Source: {metadata['filename']}\n")
            f.write(f"# Entity: {metadata['entity_col']}\n")
            f.write(f"# Features: {len(metadata['feature_cols'])}\n\n")

            # Source
            f.write(f"{source_name} = FileSource(\n")
            f.write(f'    name="{source_name}",\n')
            f.write(f'    path="{metadata["filepath"]}",\n')
            f.write(f'    timestamp_field="event_timestamp",\n')
            f.write(f'    created_timestamp_column="created_at",\n')
            f.write(f")\n\n")

            # Feature View
            f.write(f"{view_name}_features = FeatureView(\n")
            f.write(f'    name="{view_name}_features",\n')
            f.write(f"    entities=[{metadata['entity_name']}],\n")
            f.write(f"    ttl=timedelta(days=365),\n")
            f.write(f"    schema=[\n")

            # Fields
            for col in metadata["feature_cols"]:
                feast_type = infer_feast_type(metadata["df"][col].dtype)
                f.write(f'        Field(name="{col}", dtype={feast_type}),\n')

            f.write(f"    ],\n")
            f.write(f"    online=True,\n")
            f.write(f"    source={source_name},\n")
            f.write(
                f'    tags={{"source": "{metadata["filename"]}", "entity": "{metadata["entity_name"]}"}},\n'
            )
            f.write(f")\n\n")

        # Footer
        f.write("# " + "=" * 76 + "\n")
        f.write(
            f"# Generated {len(file_metadata)} feature views from {len(parquet_files)} files\n"
        )
        f.write(f"# Entities: {', '.join(sorted(entities_map.keys()))}\n")
        f.write("# " + "=" * 76 + "\n")

    print("\n" + "=" * 80)
    print(f"âœ… Generated: {output_file}")
    print(f"   Entities: {len(entities_map)}")
    print(f"   Feature Views: {len(file_metadata)}")
    print(f"   Total Features: {sum(len(m['feature_cols']) for m in file_metadata)}")
    print("=" * 80)

    return file_metadata, entities_map


if __name__ == "__main__":
    import sys

    data_dir = sys.argv[1] if len(sys.argv) > 1 else "data"
    output_file = sys.argv[2] if len(sys.argv) > 2 else "auto_features.py"

    generate_feast_code(data_dir, output_file)
